import numpy as np
import os
import io
import cv2
import warnings

# æŠ‘åˆ¶å¸¸è§çš„åº“è­¦å‘Šä¿¡æ¯
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

import torch

from utils.config import (Config,
                    eval_dict_leaf)

from demo.utils import (retrieve_text,
                  _frame_from_video,
                  setup_internvideo2)

video = cv2.VideoCapture('demo/example2.mp4')
frames = [x for x in _frame_from_video(video)]


text_candidates = ["A girl is swinging her arms.",
                   "A person is doing arm exercises.",
                   "A person is waving their hands in the air.",
                   "A person is playing tennis or badminton.",
                   "A person is driving a car.",
                   "A team is playing football.",
                   "A girl is conducting an orchestra.",
                   "A man and a dog are playing in the snow.",
                   "A man is eating a sandwich."]

config = Config.from_file('demo/internvideo2_stage2_config.py')
config = eval_dict_leaf(config)

intern_model, tokenizer = setup_internvideo2(config)

# æµ‹è¯•æ‰€æœ‰å€™é€‰æ–‡æœ¬çš„æ¦‚ç‡
texts, probs = retrieve_text(frames, text_candidates, model=intern_model, topk=len(text_candidates), config=config)

print("æ‰€æœ‰å€™é€‰æè¿°çš„åŒ¹é…æ¦‚ç‡ï¼š")
for t, p in zip(texts, probs):
    print(f'  {t} â†’ {p:.4f}')
    
print(f'\nğŸ¯ æœ€åŒ¹é…çš„æè¿°: {texts[0]} (æ¦‚ç‡: {probs[0]:.4f})')